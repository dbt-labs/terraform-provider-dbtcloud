---
page_title: "dbtcloud_bigquery_connection Resource - dbtcloud"
subcategory: ""
description: |-
  Resource to create BigQuery connections in dbt Cloud. Can be set to use OAuth for developers.
  ~> This resource is deprecated and is going to be removed in the next major release, please use the dbtcloud_global_connection resource instead to create BigQuery connections.
---

# dbtcloud_bigquery_connection (Resource)


Resource to create BigQuery connections in dbt Cloud. Can be set to use OAuth for developers.

~> This resource is deprecated and is going to be removed in the next major release, please use the `dbtcloud_global_connection` resource instead to create BigQuery connections.

## Example Usage

```terraform
resource "dbtcloud_bigquery_connection" "my_connection" {
  project_id                  = dbtcloud_project.dbt_project.id
  name                        = "Project Name"
  type                        = "bigquery"
  is_active                   = true
  gcp_project_id              = "my-gcp-project-id"
  timeout_seconds             = 100
  private_key_id              = "my-private-key-id"
  private_key                 = "ABCDEFGHIJKL"
  client_email                = "my_client_email"
  client_id                   = "my_client_di"
  auth_uri                    = "my_auth_uri"
  token_uri                   = "my_token_uri"
  auth_provider_x509_cert_url = "my_auth_provider_x509_cert_url"
  client_x509_cert_url        = "my_client_x509_cert_url"
  retries                     = 3
}

# it is also possible to set the connection to use OAuth by filling in `application_id` and `application_secret`
resource "dbtcloud_bigquery_connection" "my_connection_with_oauth" {
  project_id                  = dbtcloud_project.dbt_project.id
  name                        = "Project Name"
  type                        = "bigquery"
  is_active                   = true
  gcp_project_id              = "my-gcp-project-id"
  timeout_seconds             = 100
  private_key_id              = "my-private-key-id"
  private_key                 = "ABCDEFGHIJKL"
  client_email                = "my_client_email"
  client_id                   = "my_client_di"
  auth_uri                    = "my_auth_uri"
  token_uri                   = "my_token_uri"
  auth_provider_x509_cert_url = "my_auth_provider_x509_cert_url"
  client_x509_cert_url        = "my_client_x509_cert_url"
  retries                     = 3
  application_id              = "oauth_application_id"
  application_secret          = "oauth_secret_id"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `auth_provider_x509_cert_url` (String) Auth Provider X509 Cert URL for the Service Account
- `auth_uri` (String) Auth URI for the Service Account
- `client_email` (String) Service Account email
- `client_id` (String) Client ID of the Service Account
- `client_x509_cert_url` (String) Client X509 Cert URL for the Service Account
- `gcp_project_id` (String) GCP project ID
- `name` (String) Connection name
- `private_key` (String, Sensitive) Private key of the Service Account
- `private_key_id` (String) Private key ID of the Service Account
- `project_id` (Number) Project ID to create the connection in
- `timeout_seconds` (Number) Timeout in seconds for queries
- `token_uri` (String) Token URI for the Service Account
- `type` (String) The type of connection

### Optional

- `application_id` (String, Sensitive) The Application ID for BQ OAuth
- `application_secret` (String, Sensitive) The Application Secret for BQ OAuth
- `dataproc_cluster_name` (String) Dataproc cluster name for PySpark workloads
- `dataproc_region` (String) Google Cloud region for PySpark workloads on Dataproc
- `execution_project` (String) Project to bill for query execution
- `gcs_bucket` (String) URI for a Google Cloud Storage bucket to host Python code executed via Datapro
- `is_active` (Boolean) Whether the connection is active
- `location` (String) Location to create new Datasets in
- `maximum_bytes_billed` (Number) Max number of bytes that can be billed for a given BigQuery query
- `priority` (String) The priority with which to execute BigQuery queries (batch or interactive)
- `retries` (Number) Number of retries for queries

### Read-Only

- `connection_id` (Number) Connection Identifier
- `id` (String) The ID of this resource.
- `is_configured_for_oauth` (Boolean) Whether the connection is configured for OAuth or not

## Import

Import is supported using the following syntax:

```shell
# using  import blocks (requires Terraform >= 1.5)
import {
  to = dbtcloud_bigquery_connection.my_connection
  id = "project_id:connection_id"
}

import {
  to = dbtcloud_bigquery_connection.my_connection
  id = "12345:6789"
}

# using the older import command
terraform import dbtcloud_bigquery_connection.my_connection "project_id:connection_id"
terraform import dbtcloud_bigquery_connection.my_connection 12345:6789
```
